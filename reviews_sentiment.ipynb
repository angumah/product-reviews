{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tarfile # this is to extract the data from that .tgz file\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the data out of that .tgz\n",
    "amazon_reviews = tarfile.open('/Users/tngumah/Desktop/NLP/Final/amazon_review_polarity_csv.tgz')\n",
    "amazon_reviews.extractall('/Users/tngumah/Desktop/NLP/Final/data')\n",
    "amazon_reviews.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out what the data looks like before you get started\n",
    "# look at the training data set\n",
    "train_df = pd.read_csv('./data/amazon_review_polarity_csv/train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the test data set\n",
    "test_df = pd.read_csv('./data/amazon_review_polarity_csv/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['rating', 'title', 'review']\n",
    "train_df = train_df.head(10000)\n",
    "\n",
    "\n",
    "test_df.columns = ['rating', 'title', 'review']\n",
    "test_df = test_df.head(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   rating  10000 non-null  int64 \n",
      " 1   title   9998 non-null   object\n",
      " 2   review  10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess and clean data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the training and test DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The  DataFrame containing 'title', 'review', and 'rating' columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The preprocessed dataframe.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def clean_text(text):\n",
    "        \"\"\"\n",
    "        Lemmatizes the text, converts it to lowercase, and removes punctuation.\n",
    "        \n",
    "        Parameters:\n",
    "        - text (str): The text to clean.\n",
    "\n",
    "        Returns:\n",
    "        - str: The cleaned text.\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        # Tokenize and lemmatize\n",
    "        tokens = word_tokenize(text)\n",
    "        lemmatized_text = ' '.join(lemmatizer.lemmatize(token) for token in tokens)\n",
    "        return lemmatized_text\n",
    "\n",
    "    # Remove rows with NaN values in combined_text or sentiment\n",
    "    df = df[df['combined_text'].notna() & df['sentiment'].notna()]\n",
    "\n",
    "    return df\n",
    "\n",
    "    #lemmatize and remove stop words\n",
    "    df['combined_text'] = df['combined_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map ratings to sentiment labels\n",
    "def map_sentiment(rating):\n",
    "    \"\"\"\n",
    "    Map rating values to sentiment labels.\n",
    "\n",
    "    Parameters:\n",
    "    rating (int): Rating value (1, or 2).\n",
    "\n",
    "    Returns:\n",
    "    str: 'negative' for ratings 1 and 2, 'positive' for ratings 4 and 5.\n",
    "    \"\"\"\n",
    "    if rating == 1:\n",
    "        return 'negative'\n",
    "    elif rating == 2:\n",
    "        return 'positive'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping function to the training and test datasets\n",
    "train_df['sentiment'] = train_df['rating'].apply(map_sentiment)\n",
    "test_df['sentiment'] = test_df['rating'].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine title and review text\n",
    "train_df['combined_text'] = train_df['title'] + \" \" + train_df['review']\n",
    "test_df['combined_text'] = test_df['title'] + \" \" + test_df['review']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   rating         10000 non-null  int64 \n",
      " 1   title          10000 non-null  object\n",
      " 2   review         10000 non-null  object\n",
      " 3   sentiment      10000 non-null  object\n",
      " 4   combined_text  10000 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = preprocess_data(train_df)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9998 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   rating         9998 non-null   int64 \n",
      " 1   title          9998 non-null   object\n",
      " 2   review         9998 non-null   object\n",
      " 3   sentiment      9998 non-null   object\n",
      " 4   combined_text  9998 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 468.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocess_data(test_df)\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['combined_text'], train_df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Test set data\n",
    "X_test = test_df['combined_text']\n",
    "y_test = test_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models\n",
    "def train_and_evaluate(vectorizer, model, X_train, X_val, y_train, y_val, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train a model and evaluate its performance on validation and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    vectorizer (Vectorizer): The vectorizer to use for transforming the text data.\n",
    "    model (Classifier): The model to train.\n",
    "    X_train (list of str): Training documents.\n",
    "    X_val (list of str): Validation documents.\n",
    "    y_train (list of str): Training labels.\n",
    "    y_val (list of str): Validation labels.\n",
    "    X_test (list of str): Testing documents.\n",
    "    y_test (list of str): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Validation accuracy, validation report, validation confusion matrix,\n",
    "           test accuracy, test report, test confusion matrix.\n",
    "    \"\"\"\n",
    "    # Vectorize the training data\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    # Vectorize the validation data\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    \n",
    "    # Validate the model on the validation set\n",
    "    y_val_pred = model.predict(X_val_vec)\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    # Generate validation classification report\n",
    "    val_report = classification_report(y_val, y_val_pred)\n",
    "    # Generate validation confusion matrix\n",
    "    val_cm = confusion_matrix(y_val, y_val_pred)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    X_test_vec = vectorizer.transform(X_test)  # Vectorize the test data\n",
    "    y_test_pred = model.predict(X_test_vec)    # Predict on the test set\n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    # Generate test classification report\n",
    "    test_report = classification_report(y_test, y_test_pred)\n",
    "    # Generate test confusion matrix\n",
    "    test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    return val_accuracy, val_report, val_cm, test_accuracy, test_report, test_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizers and models\n",
    "vectorizer_tf = CountVectorizer(max_features=5000)  # Vectorizer for term frequency\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=5000)  # Vectorizer for TF-IDF\n",
    "\n",
    "model_nb = MultinomialNB()  # Naive Bayes classifier\n",
    "model_lr = LogisticRegression(max_iter=1000)  # Logistic Regression classifier\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300)  # MLP classifier\n",
    "\n",
    "# Train and evaluate models with validation and test sets\n",
    "# Naive Bayes with CountVectorizer (TF)\n",
    "val_accuracy_nb_tf, val_report_nb_tf, val_cm_nb_tf, test_accuracy_nb_tf, test_report_nb_tf, test_cm_nb_tf = train_and_evaluate(vectorizer_tf, model_nb, X_train, X_val, y_train, y_val, X_test, y_test)\n",
    "\n",
    "# Naive Bayes with TfidfVectorizer (TF-IDF)\n",
    "val_accuracy_nb_tfidf, val_report_nb_tfidf, val_cm_nb_tfidf, test_accuracy_nb_tfidf, test_report_nb_tfidf, test_cm_nb_tfidf = train_and_evaluate(vectorizer_tfidf, model_nb, X_train, X_val, y_train, y_val, X_test, y_test)\n",
    "\n",
    "# Logistic Regression with CountVectorizer (TF)\n",
    "val_accuracy_lr_tf, val_report_lr_tf, val_cm_lr_tf, test_accuracy_lr_tf, test_report_lr_tf, test_cm_lr_tf = train_and_evaluate(vectorizer_tf, model_lr, X_train, X_val, y_train, y_val, X_test, y_test)\n",
    "\n",
    "# Logistic Regression with TfidfVectorizer (TF-IDF)\n",
    "val_accuracy_lr_tfidf, val_report_lr_tfidf, val_cm_lr_tfidf, test_accuracy_lr_tfidf, test_report_lr_tfidf, test_cm_lr_tfidf = train_and_evaluate(vectorizer_tfidf, model_lr, X_train, X_val, y_train, y_val, X_test, y_test)\n",
    "\n",
    "# MLP with CountVectorizer (TF)\n",
    "val_accuracy_mlp_tf, val_report_mlp_tf, val_cm_mlp_tf, test_accuracy_mlp_tf, test_report_mlp_tf, test_cm_mlp_tf = train_and_evaluate(vectorizer_tf, model_mlp, X_train, X_val, y_train, y_val, X_test, y_test)\n",
    "\n",
    "# MLP with TfidfVectorizer (TF-IDF)\n",
    "val_accuracy_mlp_tfidf, val_report_mlp_tfidf, val_cm_mlp_tfidf, test_accuracy_mlp_tfidf, test_report_mlp_tfidf, test_cm_mlp_tfidf = train_and_evaluate(vectorizer_tfidf, model_mlp, X_train, X_val, y_train, y_val, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print evaluation results for each model (not included in the original code)\n",
    "def print_evaluation_results(model_name, val_accuracy, val_report, val_cm, test_accuracy, test_report, test_cm):\n",
    "    \"\"\"\n",
    "    Print the evaluation results for a given model.\n",
    "\n",
    "    Parameters:\n",
    "    model_name (str): The name of the model.\n",
    "    val_accuracy (float): Validation accuracy of the model.\n",
    "    val_report (str): Validation classification report of the model.\n",
    "    val_cm (ndarray): Validation confusion matrix of the model.\n",
    "    test_accuracy (float): Test accuracy of the model.\n",
    "    test_report (str): Test classification report of the model.\n",
    "    test_cm (ndarray): Test confusion matrix of the model.\n",
    "    \"\"\"\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "    print(\"Validation Classification Report:\")\n",
    "    print(val_report)\n",
    "    print(\"Validation Confusion Matrix:\")\n",
    "    print(val_cm)\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "    print(\"Test Classification Report:\")\n",
    "    print(test_report)\n",
    "    print(\"Test Confusion Matrix:\")\n",
    "    print(test_cm)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes with TF\n",
      "Validation Accuracy: 0.8385\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85      1037\n",
      "    positive       0.84      0.82      0.83       963\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[889 148]\n",
      " [175 788]]\n",
      "Test Accuracy: 0.8314662932586517\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83      4874\n",
      "    positive       0.83      0.84      0.84      5124\n",
      "\n",
      "    accuracy                           0.83      9998\n",
      "   macro avg       0.83      0.83      0.83      9998\n",
      "weighted avg       0.83      0.83      0.83      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[4026  848]\n",
      " [ 837 4287]]\n",
      "\n",
      "\n",
      "Model: Naive Bayes with TF-IDF\n",
      "Validation Accuracy: 0.835\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.85      1037\n",
      "    positive       0.85      0.80      0.82       963\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.84      0.83      0.83      2000\n",
      "weighted avg       0.84      0.83      0.83      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[904 133]\n",
      " [197 766]]\n",
      "Test Accuracy: 0.8290658131626325\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.84      0.83      4874\n",
      "    positive       0.84      0.82      0.83      5124\n",
      "\n",
      "    accuracy                           0.83      9998\n",
      "   macro avg       0.83      0.83      0.83      9998\n",
      "weighted avg       0.83      0.83      0.83      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[4092  782]\n",
      " [ 927 4197]]\n",
      "\n",
      "\n",
      "Model: Logistic Regression with TF\n",
      "Validation Accuracy: 0.857\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.86      1037\n",
      "    positive       0.85      0.85      0.85       963\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[898 139]\n",
      " [147 816]]\n",
      "Test Accuracy: 0.8477695539107821\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84      4874\n",
      "    positive       0.85      0.86      0.85      5124\n",
      "\n",
      "    accuracy                           0.85      9998\n",
      "   macro avg       0.85      0.85      0.85      9998\n",
      "weighted avg       0.85      0.85      0.85      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[4066  808]\n",
      " [ 714 4410]]\n",
      "\n",
      "\n",
      "Model: Logistic Regression with TF-IDF\n",
      "Validation Accuracy: 0.866\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87      1037\n",
      "    positive       0.87      0.85      0.86       963\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.87      0.87      0.87      2000\n",
      "weighted avg       0.87      0.87      0.87      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[911 126]\n",
      " [142 821]]\n",
      "Test Accuracy: 0.8610722144428886\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86      4874\n",
      "    positive       0.86      0.87      0.87      5124\n",
      "\n",
      "    accuracy                           0.86      9998\n",
      "   macro avg       0.86      0.86      0.86      9998\n",
      "weighted avg       0.86      0.86      0.86      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[4159  715]\n",
      " [ 674 4450]]\n",
      "\n",
      "\n",
      "Model: MLP with TF\n",
      "Validation Accuracy: 0.8425\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.85      1037\n",
      "    positive       0.83      0.85      0.84       963\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[870 167]\n",
      " [148 815]]\n",
      "Test Accuracy: 0.834366873374675\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.83      4874\n",
      "    positive       0.83      0.85      0.84      5124\n",
      "\n",
      "    accuracy                           0.83      9998\n",
      "   macro avg       0.83      0.83      0.83      9998\n",
      "weighted avg       0.83      0.83      0.83      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[3965  909]\n",
      " [ 747 4377]]\n",
      "\n",
      "\n",
      "Model: MLP with TF-IDF\n",
      "Validation Accuracy: 0.834\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.84      0.84      1037\n",
      "    positive       0.83      0.83      0.83       963\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n",
      "Validation Confusion Matrix:\n",
      "[[871 166]\n",
      " [166 797]]\n",
      "Test Accuracy: 0.8212642528505701\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.82      4874\n",
      "    positive       0.82      0.83      0.83      5124\n",
      "\n",
      "    accuracy                           0.82      9998\n",
      "   macro avg       0.82      0.82      0.82      9998\n",
      "weighted avg       0.82      0.82      0.82      9998\n",
      "\n",
      "Test Confusion Matrix:\n",
      "[[3963  911]\n",
      " [ 876 4248]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print validation and test results for each model\n",
    "print_evaluation_results(\"Naive Bayes with TF\", val_accuracy_nb_tf, val_report_nb_tf, val_cm_nb_tf, test_accuracy_nb_tf, test_report_nb_tf, test_cm_nb_tf)\n",
    "print_evaluation_results(\"Naive Bayes with TF-IDF\", val_accuracy_nb_tfidf, val_report_nb_tfidf, val_cm_nb_tfidf, test_accuracy_nb_tfidf, test_report_nb_tfidf, test_cm_nb_tfidf)\n",
    "print_evaluation_results(\"Logistic Regression with TF\", val_accuracy_lr_tf, val_report_lr_tf, val_cm_lr_tf, test_accuracy_lr_tf, test_report_lr_tf, test_cm_lr_tf)\n",
    "print_evaluation_results(\"Logistic Regression with TF-IDF\", val_accuracy_lr_tfidf, val_report_lr_tfidf, val_cm_lr_tfidf, test_accuracy_lr_tfidf, test_report_lr_tfidf, test_cm_lr_tfidf)\n",
    "print_evaluation_results(\"MLP with TF\", val_accuracy_mlp_tf, val_report_mlp_tf, val_cm_mlp_tf, test_accuracy_mlp_tf, test_report_mlp_tf, test_cm_mlp_tf)\n",
    "print_evaluation_results(\"MLP with TF-IDF\", val_accuracy_mlp_tfidf, val_report_mlp_tfidf, val_cm_mlp_tfidf, test_accuracy_mlp_tfidf, test_report_mlp_tfidf, test_cm_mlp_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the accuracy of each model\n",
    "models = [\"N_B_TF\", \"N_B_TF-IDF\", \"L_R_TF\", \"L_R_TF-IDF\", \"MLP_TF\", \"MLP_TF-IDF\"]\n",
    "val_accuracies = [val_accuracy_nb_tf, val_accuracy_nb_tfidf, val_accuracy_lr_tf, val_accuracy_lr_tfidf, val_accuracy_mlp_tf, val_accuracy_mlp_tfidf]\n",
    "test_accuracies = [test_accuracy_nb_tf, test_accuracy_nb_tfidf, test_accuracy_lr_tf, test_accuracy_lr_tfidf, test_accuracy_mlp_tf, test_accuracy_mlp_tfidf]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar chart to compare validation and test accuracies\n",
    "x = range(len(models))\n",
    "plt.bar(x, val_accuracies, width=0.2, label='Validation Accuracy', color='blue', align='center')\n",
    "plt.bar([p + 0.4 for p in x], test_accuracies, width=0.2, label='Test Accuracy', color='orange', align='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Validation vs Test Accuracy for Each Model')\n",
    "plt.xticks([p + 0.2 for p in x], models)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
